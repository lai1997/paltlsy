{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8JSu65MtRRy"
   },
   "source": [
    "# <strong>LTL Learning on GPUs</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0K2Uquon2hr"
   },
   "source": [
    "# <strong>Introduction</strong>\n",
    " Hello and welcome to our notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a7GY1w7n8CV"
   },
   "source": [
    "# <strong>Initialization</strong>\n",
    "\n",
    "To begin, please run the code below to transfer all of the necessary requirements, including the codes, dependencies, benchmarks, etc, to this notebook.\n",
    "\n",
    "Clone the repo by running the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'paltlsy'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (12/12), 12.07 MiB | 29.28 MiB/s, done.\n",
      "Resolving deltas: 100% (2/2), done.\n",
      "mv: cannot overwrite 'content/paltlsy': Directory not empty\n",
      "/home/lun/workspace/paltlsy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "! git clone https://github.com/t7uIqs22H10c/paltlsy\n",
    "! mkdir -p content\n",
    "! mv -f paltlsy/ content\n",
    "\n",
    "os.chdir('/home/lun/workspace/paltlsy/')\n",
    "print(os.getcwd())\n",
    "\n",
    "with zipfile.ZipFile('./content/paltlsy/cav-2024-submission-5511.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./content/paltlsy/')\n",
    "\n",
    "contents = os.listdir(\"./content/paltlsy/cav-2024-submission-5511\")\n",
    "for item in contents:\n",
    "    source_path = os.path.join(\"./content/paltlsy/cav-2024-submission-5511\", item)\n",
    "    destination_path = os.path.join(\"./content/paltlsy/\", item)\n",
    "    shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0aKDC3l2UXe"
   },
   "source": [
    "<div class=\"markdown-google-sans\">\n",
    "<h1>Compiling the GPU code</h1>\n",
    "</div>\n",
    "\n",
    "To compile and run the GPU code, please run the following scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oFxLpAXJsUok"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling...\n",
      "bash: nvcc: No such file or directory\n",
      "Installing bitarray...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Compiling...\")\n",
    "! nvcc --extended-lambda -I ./content/paltlsy/code/modified_libraries ./content/paltlsy/code/ltli6463.cu -o ltli6463\n",
    "print(\"Installing bitarray...\")\n",
    "#! pip install bitarray --break-system-packages\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu1z9yuSxg3p"
   },
   "source": [
    "<div class=\"markdown-google-sans\">\n",
    "<h1>Running the GPU code</h1>\n",
    "</div>\n",
    "\n",
    "Generally, you can use\n",
    "```\n",
    "! ./ltli6463 <input_file_address> <c1> <c2> <c3> <c4> <c5> <c6> <c7> <c8> <maxCost> <AprUnqChkType> <negType>\n",
    "```\n",
    "where\n",
    "1. `input_file_address` refers to the address of the input file that contains your positive and negative traces.\n",
    "2. (`c1`, `c2`, `c3`, `c4`, `c5`, `c6`, `c7`, `c8`) are 8 small positive integers for the costs of (`a`, `~`, `&`, `|`, `X`, `F`, `G`, `U`).\n",
    "3. `maxCost` parameter is an integer that sets an upper limit on the cost of the regular expression that the algorithm will search for. In most cases, you can use a reasonably large integer, such as 500, which is appropriate for our cost functions.\n",
    "4. `AprUnqChkType` is an integer in {`1`, `2`, `3`} for choosing one of the approximate uniqueness check algorithms `firstBitsPlusStrides`, `theFirstKPercent`, `ModifiedMuellerHash`.\n",
    "5. `negType` is an integer in {`1`, `2`} for choosing one of the strategies for using negation `negOfPhi` or `negForChar`.\n",
    "\n",
    "For example, to run the first example in our benchmarks, use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a9O8kwAhxfTa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to open the file.\n"
     ]
    }
   ],
   "source": [
    "# Check if connected to GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "  print(\"At 'Runtime > Change runtime type', please choose `GPU` for `Hardware accelerator`\")\n",
    "else:\n",
    "    ! ./ltli6463 ./content/paltlsy/benchmarks/existing_work/RQ1_benchmarks/flie_benchmarks/TracesFiles/abscence/Ab0.trace 1 1 1 1 1 1 1 1 500 1 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN-BQa1b1D-R"
   },
   "source": [
    "To remove the logs for the next examples, let's compile the GPU code again with the `MEASUREMENT_MODE` flag. Please run the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhbdUqLVz-s9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Compiling...\")\n",
    "! nvcc --extended-lambda -D MEASUREMENT_MODE -I /content/paltlsy/code/modified_libraries /content/paltlsy/code/ltli6463.cu -o ltli6463\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXMAN3kRBKly"
   },
   "source": [
    "We also need to install a few more libraries. So, please run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff3DPsiqBGf5"
   },
   "outputs": [],
   "source": [
    "print(\"Installing bitarray...\")\n",
    "! pip install bitarray\n",
    "print(\"Installing mona...\")\n",
    "! apt install mona\n",
    "print(\"Cloning Scarlet...\")\n",
    "! git clone https://github.com/rajarshi008/Scarlet\n",
    "%cd Scarlet\n",
    "! source ./installation.sh\n",
    "%cd ..\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-27pLQ61nQe"
   },
   "source": [
    "<div class=\"markdown-google-sans\">\n",
    "<h1>Tips for utilizing arbitrary input</h1>\n",
    "</div>\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRxAdY3J4qeR"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# # Specify the folder path\n",
    "# folder_path = \"/content/hard\"\n",
    "\n",
    "# # Remove the folder and its contents\n",
    "# shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNLVlJEykZk0"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive(\"/content/Hamming_distance\", 'zip', \"/content/Hamming_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej0i4Bwvk2P3"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(\"/content/hard.zip\", 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\"/content/hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdwho0EaK_sQ"
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def generateRandomTraces(alphabet, le, Pnum, Nnum, address = \"/content\", filePath = \"exp.trace\"):\n",
    "\n",
    "#     if Pnum + Nnum > (2**len(alphabet))**le:\n",
    "#         print(\"Inputs are not compatible.\")\n",
    "\n",
    "#     PN = set()\n",
    "\n",
    "#     while len(PN) < Pnum + Nnum:\n",
    "#         trace = tuple(random.randint(0, 2**len(alphabet) - 1) for _ in range(le))\n",
    "#         PN.add(trace)\n",
    "\n",
    "#     P = random.sample(list(PN), Pnum)\n",
    "#     N = list(set(PN) - set(P))\n",
    "\n",
    "#     Pstr = [[\",\".join(list(format(d, f'0{len(alphabet)}b'))) for d in tp] for tp in P]\n",
    "#     Pstr = [\";\".join(ls) for ls in Pstr]\n",
    "\n",
    "#     Nstr = [[\",\".join(list(format(d, f'0{len(alphabet)}b'))) for d in tp] for tp in N]\n",
    "#     Nstr = [\";\".join(ls) for ls in Nstr]\n",
    "\n",
    "#     with open(address + '/' + filePath, 'w') as file:\n",
    "#         for trace in Pstr:\n",
    "#             file.write(f\"{trace}\\n\")\n",
    "#         file.write(\"---\\n\")\n",
    "#         for trace in Nstr:\n",
    "#             file.write(f\"{trace}\\n\")\n",
    "#         file.write(\"---\\n\")\n",
    "#         file.write(\"All Operators\\n\")\n",
    "#         file.write(\"---\\n\")\n",
    "#         file.write(\",\".join(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8tN7poZNgFC"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# alphabet = ['a', 'b']\n",
    "# os.makedirs(\"/content/hard\", exist_ok=True)\n",
    "# for le in range(3, 63 + 1):\n",
    "#     address = \"/content/hard/len=\" + str(le)\n",
    "#     os.makedirs(address, exist_ok=True)\n",
    "#     for i in range(5):\n",
    "#         filePath = f\"len={le}exp={i}.trace\"\n",
    "#         generateRandomTraces(alphabet, le, 32, 32, address, filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWREduKu1txu"
   },
   "source": [
    "# <strong>Existing Work</strong>\n",
    "\n",
    "TODO: Add some explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwzUEofEh7Jx"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/paltlsy/code\")\n",
    "import json\n",
    "from dc import *\n",
    "import signal\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "def LTLOfSingleTrace(alphabet, trace, LTL=''):\n",
    "    if trace == []:\n",
    "        return LTL\n",
    "    if LTL == '':\n",
    "        LTL = f\"{'&'.join(trace[-1])}&~X({alphabet[0]}|~{alphabet[0]})\"\n",
    "    else:\n",
    "        LTL = f\"{'&'.join(trace[-1])}&X({LTL})\"\n",
    "    return LTLOfSingleTrace(alphabet, trace[:-1], LTL)\n",
    "\n",
    "def overFittedCase(alphabet, pos):\n",
    "    out = []\n",
    "    for p in pos:\n",
    "        trace = [t.split(',') for t in p.split(';')]\n",
    "        for i in range(len(trace)):\n",
    "            for j in range(len(alphabet)):\n",
    "                if trace[i][j] == '1':\n",
    "                    trace[i][j] = alphabet[j]\n",
    "                else:\n",
    "                    trace[i][j] = '~' + alphabet[j]\n",
    "        singleTraceLTL = LTLOfSingleTrace(alphabet, trace)\n",
    "        out.append(singleTraceLTL)\n",
    "    if len(out) == 1:\n",
    "        return out[0]\n",
    "    else:\n",
    "        return '|'.join([f\"({tr})\" for tr in out])\n",
    "\n",
    "def runWithTimeout(func, args, timeout):\n",
    "    class TimeoutError(Exception):\n",
    "        pass\n",
    "    def handler(signum, frame):\n",
    "        raise TimeoutError()\n",
    "    signal.signal(signal.SIGALRM, handler)\n",
    "    signal.alarm(timeout)\n",
    "    try:\n",
    "        result = func(*args)\n",
    "    except TimeoutError as exc:\n",
    "        result = 'Function timed out.'\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "    return result\n",
    "\n",
    "all_file_paths = get_all_file_paths_in_folder(\"/content/paltlsy/benchmarks/existing_work\")\n",
    "all_file_paths.sort()\n",
    "all_file_paths.sort(key = len)\n",
    "\n",
    "timeout = 2000\n",
    "maxCost = 500\n",
    "dcAlgos = [DC3, DC2, DC1]\n",
    "dcAlgoNames = ['MV D&C', 'MB D&C Type2', 'MB D&C Type1']\n",
    "AprUnqChkTyps = ['firstBitPlusStrides', 'firstKPercent', 'MuellerHash'] # Note: you cannnot change this unless you get the indices\n",
    "windows = [64, 32, 16]\n",
    "NegTyp = 2 # negOfChr only for a fair comparison with the existing work\n",
    "costfun = [1, 1, 1, 1, 1, 1, 1, maxCost] # cost of U is high to avoid using it for a fair comparison with the existing work\n",
    "\n",
    "m = len(all_file_paths)\n",
    "n = len(dcAlgos)\n",
    "p = len(AprUnqChkTyps)\n",
    "q = len(windows)\n",
    "\n",
    "allRes = []\n",
    "\n",
    "with tqdm(total = m * n * p * q) as pbar:\n",
    "\n",
    "    for filePath in all_file_paths:\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "        print('filePath = ', filePath)\n",
    "\n",
    "        with open(filePath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "        neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "        alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "        # sumTraceLen = 0\n",
    "        # for p in pos:\n",
    "        #     sumTraceLen += len(p.split(';'))\n",
    "        # for n in neg:\n",
    "        #     sumTraceLen += len(n.split(';'))\n",
    "        # aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "        ltliRes = []\n",
    "        ltlCost = []\n",
    "        timeRes = []\n",
    "\n",
    "        for dcAlgoIdx, dcAlgo in enumerate(dcAlgos):\n",
    "\n",
    "            ltliRes.append([])\n",
    "            ltlCost.append([])\n",
    "            timeRes.append([])\n",
    "\n",
    "            for AprUnqChkTypIdx, AprUnqChkTyp in enumerate(AprUnqChkTyps):\n",
    "\n",
    "                ltliRes[-1].append([])\n",
    "                ltlCost[-1].append([])\n",
    "                timeRes[-1].append([])\n",
    "\n",
    "                for window in windows:\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    res = runWithTimeout(dcAlgo, [window, pos, neg, alphabet, costfun, maxCost, AprUnqChkTypIdx + 1, NegTyp], timeout=timeout)\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    if 'timed out' in res:\n",
    "                        LTLcost = -1\n",
    "                    elif 'not_found' in res:\n",
    "                        LTLcost = -2\n",
    "                    elif 'too long' in res:\n",
    "                        LTLcost = -3\n",
    "                    else:\n",
    "                        # verifying the result\n",
    "                        resultIsCorrect = not False in LTLmatch(pos, alphabet, res)\n",
    "                        resultIsCorrect &= not True in LTLmatch(neg, alphabet, res)\n",
    "                        if resultIsCorrect:\n",
    "                            LTLcost = c(res)\n",
    "                        else:\n",
    "                            res = 'with error: ' + res\n",
    "                            LTLcost = -4\n",
    "\n",
    "                    ltliRes[-1][-1].append(res)\n",
    "                    ltlCost[-1][-1].append(LTLcost)\n",
    "                    timeRes[-1][-1].append(round(end_time - start_time, 3))\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "                print()\n",
    "                print()\n",
    "                print('dcAlgo =', dcAlgoNames[dcAlgoIdx], ', AprUnqChkTyp =', AprUnqChkTyps[AprUnqChkTypIdx])\n",
    "                print(timeRes[-1][-1])\n",
    "                print()\n",
    "\n",
    "        # #the over-fitted case\n",
    "        # overFittedLTL = overFittedCase(alphabet.split(','), pos)\n",
    "        # overFittedCost = c(overFittedLTL)\n",
    "\n",
    "        allRes.append([filePath, timeout, dcAlgoNames, AprUnqChkTyps, windows, ltliRes, ltlCost, timeRes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Pp-ejWi5zuq"
   },
   "outputs": [],
   "source": [
    "allRes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grR_Wpbocr00"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# backup\n",
    "with open(\"/content/allRes\", 'w') as file:\n",
    "    file.write(json.dumps(allRes))\n",
    "\n",
    "files.download(\"/content/allRes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1Z8bJSjt227"
   },
   "outputs": [],
   "source": [
    "# allRes = []\n",
    "# import json\n",
    "# with open(\"/content/allRes\", 'r') as file:\n",
    "#     allRes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ms1GKBRswEV"
   },
   "outputs": [],
   "source": [
    "# # Scarlet\n",
    "\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "# from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "# def scarlet(input_file_path):\n",
    "\n",
    "#     # timeout is something big enough as we control the timing from somewhere out of the Scarlet\n",
    "#     learner = LTLlearner(input_file = input_file_path, timeout = 100000)\n",
    "\n",
    "#     out = learner.learn()\n",
    "\n",
    "#     try:\n",
    "#         return str(out[0])\n",
    "#     except:\n",
    "#         return str(out)\n",
    "\n",
    "# folder_path = \"/content/Scarlet\"\n",
    "# if not os.path.exists(folder_path):\n",
    "#     os.makedirs(folder_path)\n",
    "\n",
    "# with tqdm(total = len(allRes)) as pbar:\n",
    "\n",
    "#     for i in range(len(allRes)):\n",
    "\n",
    "#         filePath = allRes[i][0]\n",
    "#         print(filePath)\n",
    "\n",
    "#         start_time = time.time()\n",
    "#         res = runWithTimeout(scarlet, [filePath], timeout=timeout)\n",
    "#         end_time = time.time()\n",
    "\n",
    "#         if 'timed out' in res or end_time - start_time > timeout:\n",
    "#             ScarletRes = ['', timeout]\n",
    "#         if 'Error' in res or 'error' in res:\n",
    "#             ScarletRes = ['error', 'error']\n",
    "#         else:\n",
    "#             ScarletRes = [res, round(end_time - start_time, 3)]\n",
    "\n",
    "#         allRes[i].insert(2, ScarletRes)\n",
    "#         print()\n",
    "\n",
    "#         # backup\n",
    "#         with open(\"/content/allRes\", 'w') as file:\n",
    "#             file.write(json.dumps(allRes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-hiyipedWWq"
   },
   "outputs": [],
   "source": [
    "# Scarlet\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "def scarlet(input_file_path):\n",
    "\n",
    "    # timeout is something big enough as we control the timing from somewhere out of the Scarlet\n",
    "    learner = LTLlearner(input_file = input_file_path, timeout = 100000)\n",
    "\n",
    "    out = learner.learn()\n",
    "\n",
    "    try:\n",
    "        return str(out[0])\n",
    "    except:\n",
    "        return str(out)\n",
    "\n",
    "folder_path = \"/content/Scarlet\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "with tqdm(total = len(allRes)) as pbar:\n",
    "\n",
    "    for i in range(len(allRes)):\n",
    "\n",
    "        filePath = allRes[i][0]\n",
    "        print(filePath)\n",
    "\n",
    "        if len(allRes[i]) < 9:\n",
    "\n",
    "            start_time = time.time()\n",
    "            res = runWithTimeout(scarlet, [filePath], timeout=timeout)\n",
    "            end_time = time.time()\n",
    "\n",
    "            if 'timed out' in res or end_time - start_time > timeout:\n",
    "                ScarletRes = ['', timeout]\n",
    "            if 'Error' in res or 'error' in res:\n",
    "                ScarletRes = ['error', 'error']\n",
    "            else:\n",
    "                ScarletRes = [res, round(end_time - start_time, 3)]\n",
    "\n",
    "            allRes[i].insert(2, ScarletRes)\n",
    "            print()\n",
    "\n",
    "            # backup\n",
    "            with open(\"/content/allRes\", 'w') as file:\n",
    "                file.write(json.dumps(allRes))\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih2-f0ZNnc0E"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/allRes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_CCkdmNspqA"
   },
   "outputs": [],
   "source": [
    "# for i in range(len(allRes)):\n",
    "#     if allRes[i][2][0] == 'Function timed out.':\n",
    "#         allRes[i][2] = ['', timeout]\n",
    "#         print(\"hit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0QIYUbsKfbj"
   },
   "outputs": [],
   "source": [
    "# allRes = []\n",
    "# import json\n",
    "# with open(\"/content/allRes\", 'r') as file:\n",
    "#     allRes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zi_i2b2Unbjy"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# report = []\n",
    "\n",
    "# dc = ['MV', 'MB2', 'MB1']\n",
    "# ap = ['FBS', 'FKP', 'Hsh']\n",
    "# wn = ['64', '32', '16']\n",
    "\n",
    "# headers = ['Group', 'FileName', '#P', '#N', 'AveLen', 'Alphabet', 'Scarlet']\n",
    "\n",
    "# for i in range(len(dc)):\n",
    "#     for j in range(len(ap)):\n",
    "#         for k in range(len(wn)):\n",
    "#             headers.append(f\"{dc[i]}-{ap[j]}-{wn[k]}\")\n",
    "\n",
    "# for res in allRes:\n",
    "\n",
    "#     report.append([])\n",
    "\n",
    "#     filePath = res[0]\n",
    "\n",
    "#     group = '_'.join(filePath.split('/')[5:-1]).replace('_TracesFiles', '')\n",
    "#     group = group.replace('_benchmarks', '').replace('__', '_').replace('__', '_')\n",
    "#     fileName = filePath.split('/')[-1].split('.trace')[0]\n",
    "\n",
    "#     with open(filePath, 'r') as file:\n",
    "#         content = file.read()\n",
    "\n",
    "#     pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "#     neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "#     alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "#     sumTraceLen = 0\n",
    "#     for p in pos:\n",
    "#         sumTraceLen += len(p.split(';'))\n",
    "#     for n in neg:\n",
    "#         sumTraceLen += len(n.split(';'))\n",
    "#     aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "#     report[-1].append(group)\n",
    "#     report[-1].append(fileName)\n",
    "#     report[-1].append(len(pos))\n",
    "#     report[-1].append(len(neg))\n",
    "#     report[-1].append(round(aveTraceLen, 1))\n",
    "#     report[-1].append(alphabet)\n",
    "\n",
    "#     # Scarlet\n",
    "#     if res[2][0] == '':\n",
    "#         report[-1].append(f\"('OOT, {timeout})\")\n",
    "#     elif res[2][0] == '[]':\n",
    "#         report[-1].append(f\"('OOM', {res[2][1]})\")\n",
    "#     else:\n",
    "#         report[-1].append(f\"({c(res[2][0])}, {res[2][1]})\")\n",
    "\n",
    "#     # GPU code\n",
    "#     for i in range(len(allRes[0][3])):\n",
    "#         for j in range(len(allRes[0][4])):\n",
    "#             for k in range(len(allRes[0][5])):\n",
    "#                 report[-1].append(f\"({c(res[6][i][j][k])}, {res[8][i][j][k]})\")\n",
    "\n",
    "# with open(\"report.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     writer.writerows(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiYBp-mkLTxA"
   },
   "outputs": [],
   "source": [
    "# # only length\n",
    "\n",
    "# import csv\n",
    "\n",
    "# def c(ltl):\n",
    "#     return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "# report = []\n",
    "\n",
    "# dc = ['MV', 'MB2', 'MB1']\n",
    "# ap = ['FBS', 'FKP', 'Hsh']\n",
    "# wn = ['64', '32', '16']\n",
    "\n",
    "# headers = ['Group', 'FileName', '#P', '#N', 'AveLen', 'Alphabet', 'Scarlet']\n",
    "\n",
    "# for i in range(len(dc)):\n",
    "#     for j in range(len(ap)):\n",
    "#         for k in range(len(wn)):\n",
    "#             headers.append(f\"{dc[i]}-{ap[j]}-{wn[k]}\")\n",
    "\n",
    "# for res in allRes:\n",
    "\n",
    "#     report.append([])\n",
    "\n",
    "#     filePath = res[0]\n",
    "\n",
    "#     group = '_'.join(filePath.split('/')[5:-1]).replace('_TracesFiles', '')\n",
    "#     group = group.replace('_benchmarks', '').replace('__', '_').replace('__', '_')\n",
    "#     fileName = filePath.split('/')[-1].split('.trace')[0]\n",
    "\n",
    "#     with open(filePath, 'r') as file:\n",
    "#         content = file.read()\n",
    "\n",
    "#     pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "#     neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "#     alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "#     sumTraceLen = 0\n",
    "#     for p in pos:\n",
    "#         sumTraceLen += len(p.split(';'))\n",
    "#     for n in neg:\n",
    "#         sumTraceLen += len(n.split(';'))\n",
    "#     aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "#     report[-1].append(group)\n",
    "#     report[-1].append(fileName)\n",
    "#     report[-1].append(len(pos))\n",
    "#     report[-1].append(len(neg))\n",
    "#     report[-1].append(round(aveTraceLen, 1))\n",
    "#     report[-1].append(alphabet)\n",
    "\n",
    "#     # Scarlet\n",
    "#     if res[2][0] == '':\n",
    "#         report[-1].append('OOT')\n",
    "#     elif res[2][0] == '[]':\n",
    "#         report[-1].append('OOM')\n",
    "#     else:\n",
    "#         report[-1].append(c(str(res[2][0])))\n",
    "\n",
    "#     # GPU code\n",
    "#     for i in range(len(allRes[0][3])):\n",
    "#         for j in range(len(allRes[0][4])):\n",
    "#             for k in range(len(allRes[0][5])):\n",
    "#                 report[-1].append(str(c(res[6][i][j][k])))\n",
    "\n",
    "# with open(\"report.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     writer.writerows(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUc-zyJQLSOY"
   },
   "outputs": [],
   "source": [
    "# # only time\n",
    "\n",
    "# import csv\n",
    "\n",
    "# timeout = 2000\n",
    "\n",
    "# report = []\n",
    "\n",
    "# dc = ['MV', 'MB2', 'MB1']\n",
    "# ap = ['FBS', 'FKP', 'Hsh']\n",
    "# wn = ['64', '32', '16']\n",
    "\n",
    "# headers = ['Group', 'FileName', '#P', '#N', 'AveLen', 'Alphabet', 'Scarlet']\n",
    "\n",
    "# for i in range(len(dc)):\n",
    "#     for j in range(len(ap)):\n",
    "#         for k in range(len(wn)):\n",
    "#             headers.append(f\"{dc[i]}-{ap[j]}-{wn[k]}\")\n",
    "\n",
    "# for res in allRes:\n",
    "\n",
    "#     report.append([])\n",
    "\n",
    "#     filePath = res[0]\n",
    "\n",
    "#     group = '_'.join(filePath.split('/')[5:-1]).replace('_TracesFiles', '')\n",
    "#     group = group.replace('_benchmarks', '').replace('__', '_').replace('__', '_')\n",
    "#     fileName = filePath.split('/')[-1].split('.trace')[0]\n",
    "\n",
    "#     with open(filePath, 'r') as file:\n",
    "#         content = file.read()\n",
    "\n",
    "#     pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "#     neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "#     alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "#     sumTraceLen = 0\n",
    "#     for p in pos:\n",
    "#         sumTraceLen += len(p.split(';'))\n",
    "#     for n in neg:\n",
    "#         sumTraceLen += len(n.split(';'))\n",
    "#     aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "#     report[-1].append(group)\n",
    "#     report[-1].append(fileName)\n",
    "#     report[-1].append(len(pos))\n",
    "#     report[-1].append(len(neg))\n",
    "#     report[-1].append(round(aveTraceLen, 1))\n",
    "#     report[-1].append(alphabet)\n",
    "\n",
    "#     # Scarlet\n",
    "#     if res[2][0] == '':\n",
    "#         report[-1].append(str(timeout))\n",
    "#     elif res[2][0] == '[]':\n",
    "#         report[-1].append(str(res[2][1]))\n",
    "#     else:\n",
    "#         report[-1].append(str(res[2][1]))\n",
    "\n",
    "#     # GPU code\n",
    "#     for i in range(len(allRes[0][3])):\n",
    "#         for j in range(len(allRes[0][4])):\n",
    "#             for k in range(len(allRes[0][5])):\n",
    "#                 report[-1].append(str(res[8][i][j][k]))\n",
    "\n",
    "# with open(\"report.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     writer.writerows(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUr5HprJ5Gub"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vR_HnbV7sReN"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "# Scarlet's report\n",
    "\n",
    "report = [0, 0, 0, 0, 0]\n",
    "for res in allRes:\n",
    "    ltl = res[2][0]\n",
    "    time = res[2][1]\n",
    "    if ltl == '':\n",
    "        report[3] += 1\n",
    "    elif ltl == '[]':\n",
    "        report[4] += 1\n",
    "    else:\n",
    "        report[0] += c(ltl)\n",
    "        report[1] += time\n",
    "        report[2] += 1\n",
    "\n",
    "print(report)\n",
    "\n",
    "data = [[]]\n",
    "headers = ['Scarlet\\'s AveLTLCost', 'Scarlet\\'s AveTime', 'Scarlet\\'s OOT', 'Scarlet\\'s OOM']\n",
    "\n",
    "data[0].append(str(round(report[0] / report[2], 3)))\n",
    "data[0].append(str(round(report[1] / report[2], 3)) + 's')\n",
    "data[0].append(str(round(report[3] * 100 / len(allRes), 1)) + '%')\n",
    "data[0].append(str(round(report[4] * 100 / len(allRes), 1)) + '%')\n",
    "\n",
    "table = tabulate(data, headers, tablefmt=\"fancy_grid\", stralign=\"center\")\n",
    "\n",
    "with open(\"Scarlet_Report.txt\", \"w\") as file:\n",
    "    file.write(table)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pe8S-MpAt68"
   },
   "outputs": [],
   "source": [
    "# GPU report for all\n",
    "\n",
    "report = []\n",
    "for i in range(len(allRes[0][3])):\n",
    "    report.append([])\n",
    "    for j in range(len(allRes[0][4])):\n",
    "        report[-1].append([])\n",
    "        for k in range(len(allRes[0][5])):\n",
    "            report[-1][-1].append([0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for res in allRes:\n",
    "    for i in range(len(allRes[0][3])):\n",
    "        for j in range(len(allRes[0][4])):\n",
    "            for k in range(len(allRes[0][5])):\n",
    "                if res[7][i][j][k] == -1:\n",
    "                    report[i][j][k][3] += 1\n",
    "                elif res[7][i][j][k] == -2:\n",
    "                    report[i][j][k][4] += 1\n",
    "                elif res[7][i][j][k] == -3:\n",
    "                    report[i][j][k][5] += 1\n",
    "                elif res[7][i][j][k] == -4:\n",
    "                    report[i][j][k][6] += 1\n",
    "                else:\n",
    "                    report[i][j][k][0] += res[7][i][j][k]\n",
    "                    report[i][j][k][1] += res[8][i][j][k]\n",
    "                    report[i][j][k][2] += 1\n",
    "\n",
    "data = []\n",
    "headers = ['D&C', 'AppUnqChkType', 'WinSize', 'AveLTLCost', 'AveTime', 'Correct', 'OOT', 'OOM', 'TooLong', 'WrongLTL']\n",
    "\n",
    "for i in range(len(allRes[0][3])):\n",
    "    for j in range(len(allRes[0][4])):\n",
    "        for k in range(len(allRes[0][5])):\n",
    "            data.append([str(allRes[0][3][i]),\n",
    "                          str(allRes[0][4][j]),\n",
    "                          str(allRes[0][5][k]),\n",
    "                          str(round(report[i][j][k][0] / report[i][j][k][2], 3)),\n",
    "                          str(round(report[i][j][k][1] / report[i][j][k][2], 3)) + 's',\n",
    "                          str(round(report[i][j][k][2] * 100 / len(allRes)))     + '%',\n",
    "                          str(round(report[i][j][k][3] * 100 / len(allRes)))     + '%',\n",
    "                          str(round(report[i][j][k][4] * 100 / len(allRes)))     + '%',\n",
    "                          str(round(report[i][j][k][5] * 100 / len(allRes)))     + '%',\n",
    "                          str(round(report[i][j][k][6] * 100 / len(allRes)))     + '%'])\n",
    "\n",
    "table = tabulate(data, headers, tablefmt=\"fancy_grid\", stralign=\"center\")\n",
    "\n",
    "with open(\"GPU_Report_All.txt\", \"w\") as file:\n",
    "    file.write(table)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlUtCPNbAwLr"
   },
   "outputs": [],
   "source": [
    "# GPU report for those which Scarlet does not run OOM or OOT\n",
    "\n",
    "report = []\n",
    "for i in range(len(allRes[0][3])):\n",
    "    report.append([])\n",
    "    for j in range(len(allRes[0][4])):\n",
    "        report[-1].append([])\n",
    "        for k in range(len(allRes[0][5])):\n",
    "            report[-1][-1].append([0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for res in allRes:\n",
    "\n",
    "    ScarletLTL = res[2][0]\n",
    "    if ScarletLTL == '' or ScarletLTL == '[]':\n",
    "        continue\n",
    "\n",
    "    for i in range(len(allRes[0][3])):\n",
    "        for j in range(len(allRes[0][4])):\n",
    "            for k in range(len(allRes[0][5])):\n",
    "                if res[7][i][j][k] == -1:\n",
    "                    report[i][j][k][3] += 1\n",
    "                elif res[7][i][j][k] == -2:\n",
    "                    report[i][j][k][4] += 1\n",
    "                elif res[7][i][j][k] == -3:\n",
    "                    report[i][j][k][5] += 1\n",
    "                elif res[7][i][j][k] == -4:\n",
    "                    report[i][j][k][6] += 1\n",
    "                else:\n",
    "                    report[i][j][k][0] += res[7][i][j][k]\n",
    "                    report[i][j][k][1] += res[8][i][j][k]\n",
    "                    report[i][j][k][2] += 1\n",
    "\n",
    "print(report)\n",
    "\n",
    "data = []\n",
    "headers = ['D&C', 'AppUnqChkType', 'WinSize', 'AveLTLCost', 'AveTime', 'Correct', 'OOT', 'OOM', 'TooLong', 'WrongLTL']\n",
    "\n",
    "for i in range(len(allRes[0][3])):\n",
    "    for j in range(len(allRes[0][4])):\n",
    "        for k in range(len(allRes[0][5])):\n",
    "            size = report[i][j][k][2]\n",
    "            data.append([str(allRes[0][3][i]),\n",
    "                         str(allRes[0][4][j]),\n",
    "                         str(allRes[0][5][k]),\n",
    "                         str(round(report[i][j][k][0]       / size, 3)),\n",
    "                         str(round(report[i][j][k][1]       / size, 3)) + 's',\n",
    "                         str(round(report[i][j][k][2] * 100 / size))    + '%',\n",
    "                         str(round(report[i][j][k][3] * 100 / size))    + '%',\n",
    "                         str(round(report[i][j][k][4] * 100 / size))    + '%',\n",
    "                         str(round(report[i][j][k][5] * 100 / size))    + '%',\n",
    "                         str(round(report[i][j][k][6] * 100 / size))    + '%'])\n",
    "\n",
    "table = tabulate(data, headers, tablefmt=\"fancy_grid\", stralign=\"center\")\n",
    "\n",
    "with open(\"GPU_Report_On_Scarlet.txt\", \"w\") as file:\n",
    "    file.write(table)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEOW6gwzhV8T"
   },
   "source": [
    "# <strong>Hard Examples: Hamming Distance</strong>\n",
    "\n",
    "TODO: Add some explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FWzJrDih5kP"
   },
   "outputs": [],
   "source": [
    "# # Generating Hamming examples\n",
    "\n",
    "# import os\n",
    "# import random\n",
    "# from itertools import combinations\n",
    "\n",
    "# def NegGenerator(trace, delta):\n",
    "#     toBeChangedIndices = list(combinations(range(0, len(trace) + 1, 2), delta))\n",
    "#     output = []\n",
    "#     for tp in toBeChangedIndices:\n",
    "#         tr = list(trace)\n",
    "#         for index in tp:\n",
    "#             if tr[index] == '0':\n",
    "#                 tr[index] = '1'\n",
    "#             else:\n",
    "#                 tr[index] = '0'\n",
    "#         output.append(''.join(tr))\n",
    "#     return output\n",
    "\n",
    "# def HardExpGen(le, delta, repeat = 1, address = \"/content\", filename = ''):\n",
    "\n",
    "#     random.seed(0)\n",
    "\n",
    "#     alphabet = ['a', 'b']\n",
    "\n",
    "#     P = set()\n",
    "#     while len(P) < repeat:\n",
    "#         trace = tuple(random.randint(0, 2**len(alphabet) - 1) for _ in range(le))\n",
    "#         P.add(trace)\n",
    "\n",
    "#     P = [[\",\".join(list(format(d, f'0{len(alphabet)}b'))) for d in tp] for tp in P]\n",
    "#     P = [\";\".join(ls) for ls in P]\n",
    "\n",
    "#     N = [NegGenerator(trace, delta) for trace in P]\n",
    "\n",
    "#     if repeat == 1:\n",
    "#         with open(f\"{address}/{filename}.trace\", 'w') as file:\n",
    "#             file.write(f\"{P[0]}\\n\")\n",
    "#             file.write(\"---\\n\")\n",
    "#             for trace in N[0]:\n",
    "#                 file.write(f\"{trace}\\n\")\n",
    "#             file.write(\"---\\n\")\n",
    "#             file.write(\"All Operators\\n\")\n",
    "#             file.write(\"---\\n\")\n",
    "#             file.write(\",\".join(alphabet))\n",
    "#     else:\n",
    "#         for i in range(len(P)):\n",
    "#             with open(f\"{address}/{filename}_exp{i}.trace\", 'w') as file:\n",
    "#                 file.write(f\"{P[i]}\\n\")\n",
    "#                 file.write(\"---\\n\")\n",
    "#                 for trace in N[i]:\n",
    "#                     file.write(f\"{trace}\\n\")\n",
    "#                 file.write(\"---\\n\")\n",
    "#                 file.write(\"All Operators\\n\")\n",
    "#                 file.write(\"---\\n\")\n",
    "#                 file.write(\",\".join(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5umAwoXwCAV"
   },
   "outputs": [],
   "source": [
    "# os.makedirs(\"/content/Hamming_distance\", exist_ok=True)\n",
    "\n",
    "# for delta in [1, 2]:\n",
    "\n",
    "#     address = f\"/content/Hamming_distance/delta={str(delta)}\"\n",
    "#     os.makedirs(address, exist_ok=True)\n",
    "\n",
    "#     for le in range(3, 63 + 1, 3):\n",
    "\n",
    "#         address = f\"/content/Hamming_distance/delta={str(delta)}\"\n",
    "#         os.makedirs(address, exist_ok=True)\n",
    "#         filename = f\"delta={str(delta)}_len={str(le)}\"\n",
    "\n",
    "#         HardExpGen(le, delta, 1, address, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBkOH2fC1mVd"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/paltlsy/code')\n",
    "import json\n",
    "from dc import *\n",
    "import signal\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "def LTLOfSingleTrace(alphabet, trace, LTL=''):\n",
    "    if trace == []:\n",
    "        return LTL\n",
    "    if LTL == '':\n",
    "        LTL = f\"{'&'.join(trace[-1])}&~X({alphabet[0]}|~{alphabet[0]})\"\n",
    "    else:\n",
    "        LTL = f\"{'&'.join(trace[-1])}&X({LTL})\"\n",
    "    return LTLOfSingleTrace(alphabet, trace[:-1], LTL)\n",
    "\n",
    "def overFittedCase(alphabet, pos):\n",
    "    out = []\n",
    "    for p in pos:\n",
    "        trace = [t.split(',') for t in p.split(';')]\n",
    "        for i in range(len(trace)):\n",
    "            for j in range(len(alphabet)):\n",
    "                if trace[i][j] == '1':\n",
    "                    trace[i][j] = alphabet[j]\n",
    "                else:\n",
    "                    trace[i][j] = '~' + alphabet[j]\n",
    "        singleTraceLTL = LTLOfSingleTrace(alphabet, trace)\n",
    "        out.append(singleTraceLTL)\n",
    "    if len(out) == 1:\n",
    "        return out[0]\n",
    "    else:\n",
    "        return '|'.join([f\"({tr})\" for tr in out])\n",
    "\n",
    "def runWithTimeout(func, args, timeout):\n",
    "    class TimeoutError(Exception):\n",
    "        pass\n",
    "    def handler(signum, frame):\n",
    "        raise TimeoutError()\n",
    "    signal.signal(signal.SIGALRM, handler)\n",
    "    signal.alarm(timeout)\n",
    "    try:\n",
    "        result = func(*args)\n",
    "    except TimeoutError as exc:\n",
    "        result = \"Function timed out.\"\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "    return result\n",
    "\n",
    "all_file_paths = get_all_file_paths_in_folder(\"/content/paltlsy/benchmarks/Hamming_distance/delta=1\")\n",
    "all_file_paths.sort()\n",
    "all_file_paths.sort(key = len)\n",
    "\n",
    "timeout = 2000\n",
    "maxCost = 500\n",
    "dcAlgos = [DC3, DC2, DC1]\n",
    "dcAlgoNames = ['MV D&C', 'MB D&C Type2', 'MB D&C Type1']\n",
    "AprUnqChkTyps = ['firstBitPlusStrides', 'firstKPercent', 'MuellerHash'] # Note: you cannnot change this unless you get the indices\n",
    "windows = [64, 32, 16]\n",
    "NegTyp = 2 # negOfChr only for a fair comparison with the existing work\n",
    "costfun = [1, 1, 1, 1, 1, 1, 1, maxCost] # cost of U is high to avoid using it for a fair comparison with the existing work\n",
    "\n",
    "m = len(dcAlgos)\n",
    "n = len(all_file_paths)\n",
    "p = len(AprUnqChkTyps)\n",
    "q = len(windows)\n",
    "\n",
    "allRes = []\n",
    "\n",
    "with tqdm(total = m * n * p * q) as pbar:\n",
    "\n",
    "    for filePath in all_file_paths:\n",
    "\n",
    "        print()\n",
    "        print(filePath)\n",
    "        print()\n",
    "\n",
    "        with open(filePath, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "        neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "        alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "        sumTraceLen = 0\n",
    "        for p in pos:\n",
    "            sumTraceLen += len(p.split(';'))\n",
    "        for n in neg:\n",
    "            sumTraceLen += len(n.split(';'))\n",
    "        aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "        info = f\", ({len(''.join(alphabet.split(',')))}, {len(pos)}, {len(neg)}, {aveTraceLen})\"\n",
    "\n",
    "        ltliRes = []\n",
    "        costRes = []\n",
    "        timeRes = []\n",
    "\n",
    "        for dcAlgoIdx, dcAlgo in enumerate(dcAlgos):\n",
    "\n",
    "            ltliRes.append([])\n",
    "            costRes.append([])\n",
    "            timeRes.append([])\n",
    "\n",
    "            for AprUnqChkTypIdx, AprUnqChkTyp in enumerate(AprUnqChkTyps):\n",
    "\n",
    "                ltliRes[-1].append([])\n",
    "                costRes[-1].append([])\n",
    "                timeRes[-1].append([])\n",
    "\n",
    "                for window in windows:\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    res = runWithTimeout(dcAlgo, (window, pos, neg, alphabet, costfun, maxCost, AprUnqChkTypIdx + 1, NegTyp), timeout=timeout)\n",
    "                    end_time = time.time()\n",
    "\n",
    "                    if \"timed out\" in res:\n",
    "                        LTLcost = -1\n",
    "                    elif \"not_found\" in res:\n",
    "                        LTLcost = -2\n",
    "                    elif \"too long\" in res:\n",
    "                        LTLcost = -3\n",
    "                    else:\n",
    "                        # verifying the result\n",
    "                        resultIsCorrect = not False in LTLmatch(pos, alphabet, res)\n",
    "                        resultIsCorrect &= not True in LTLmatch(neg, alphabet, res)\n",
    "                        if resultIsCorrect:\n",
    "                            LTLcost = c(res)\n",
    "                        else:\n",
    "                            res = \"with error: \" + res\n",
    "                            LTLcost = -4\n",
    "\n",
    "                    ltliRes[-1][-1].append(res)\n",
    "                    costRes[-1][-1].append(LTLcost)\n",
    "                    timeRes[-1][-1].append(round(end_time - start_time, 3))\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "                print()\n",
    "                print(\"dcAlgo =\", dcAlgoNames[dcAlgoIdx], \"AprUnqChkTyp =\", AprUnqChkTyps[AprUnqChkTypIdx])\n",
    "                print(costRes[-1][-1])\n",
    "                print(timeRes[-1][-1])\n",
    "                print()\n",
    "\n",
    "        #the over-fitted case\n",
    "        overFittedLTL = overFittedCase(alphabet.split(','), pos)\n",
    "        overFittedCost = c(overFittedLTL)\n",
    "\n",
    "        allRes.append([filePath, info, '', '', '', dcAlgoNames, AprUnqChkTyps, windows, ltliRes, costRes, timeRes, '', overFittedCost])\n",
    "\n",
    "# backup\n",
    "with open(\"/content/allRes\", 'w') as file:\n",
    "    file.write(json.dumps(allRes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWmOF0es9scT"
   },
   "outputs": [],
   "source": [
    "# Scarlet\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "def scarlet(input_file_path):\n",
    "\n",
    "    # timeout is something big enough as we control the timing from somewhere out of the Scarlet\n",
    "    learner = LTLlearner(input_file = input_file_path, timeout = 2000)\n",
    "\n",
    "    out = learner.learn()\n",
    "\n",
    "    try:\n",
    "        return str(out[0])\n",
    "    except:\n",
    "        return str(out)\n",
    "\n",
    "all_file_paths = get_all_file_paths_in_folder(\"/content/paltlsy/benchmarks/Hamming_distance/delta=2\")\n",
    "all_file_paths.sort()\n",
    "all_file_paths.sort(key = len)\n",
    "\n",
    "folder_path = \"/content/Scarlet\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for filePath in all_file_paths:\n",
    "\n",
    "    print()\n",
    "    print(filePath)\n",
    "\n",
    "    start_time = time.time()\n",
    "    res = runWithTimeout(scarlet, [filePath], timeout=timeout)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if 'timed out' in res:\n",
    "        ScarletRes = ['', timeout]\n",
    "    else:\n",
    "        ScarletRes = [res, round(end_time - start_time, 3)]\n",
    "\n",
    "    print(ScarletRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IWk17uH-u_S"
   },
   "outputs": [],
   "source": [
    "# # Scarlet\n",
    "\n",
    "# import time\n",
    "# from tqdm import tqdm\n",
    "# from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "# def scarlet(input_file_path):\n",
    "\n",
    "#     folder_path = \"/content/Scarlet\"\n",
    "#     if not os.path.exists(folder_path):\n",
    "#         os.makedirs(folder_path)\n",
    "\n",
    "#     # timeout is something big enough as we control the timing from somewhere out of the Scarlet\n",
    "#     learner = LTLlearner(input_file = input_file_path, timeout = 100000)\n",
    "\n",
    "#     print(learner.learn())\n",
    "#     return str(learner.learn()[0])\n",
    "\n",
    "# with tqdm(total = len(allRes)) as pbar:\n",
    "\n",
    "#     for i in range(len(allRes)):\n",
    "\n",
    "#         filePath = allRes[i][0]\n",
    "#         print(filePath)\n",
    "\n",
    "#         start_time = time.time()\n",
    "#         res = runWithTimeout(scarlet, [filePath], timeout=timeout)\n",
    "#         end_time = time.time()\n",
    "\n",
    "#         if 'timed out' in res:\n",
    "#             ScarletRes = ['', timeout]\n",
    "#         else:\n",
    "#             ScarletRes = [res, round(end_time - start_time, 3)]\n",
    "\n",
    "#         pbar.update(1)\n",
    "\n",
    "#         allRes[i].insert(2, ScarletRes)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AR02RWa8w2B2"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "report = []\n",
    "\n",
    "dc = ['MV', 'MB2', 'MB1']\n",
    "ap = ['FBS', 'FKP', 'Hsh']\n",
    "wn = ['64', '32', '16']\n",
    "\n",
    "headers = ['Group', 'FileName', '#P', '#N', 'AveLen', 'Alphabet', 'Scarlet']\n",
    "\n",
    "for i in range(len(dc)):\n",
    "    for j in range(len(ap)):\n",
    "        for k in range(len(wn)):\n",
    "            headers.append(f\"{dc[i]}-{ap[j]}-{wn[k]}\")\n",
    "\n",
    "for res in allRes:\n",
    "\n",
    "    report.append([])\n",
    "\n",
    "    filePath = res[0]\n",
    "\n",
    "    group = '_'.join(filePath.split('/')[5:-1]).replace('_TracesFiles', '')\n",
    "    group = group.replace('_benchmarks', '').replace('__', '_').replace('__', '_')\n",
    "    fileName = filePath.split('/')[-1].split('.trace')[0]\n",
    "\n",
    "    with open(filePath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "    neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "    alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "    sumTraceLen = 0\n",
    "    for p in pos:\n",
    "        sumTraceLen += len(p.split(';'))\n",
    "    for n in neg:\n",
    "        sumTraceLen += len(n.split(';'))\n",
    "    aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "    report[-1].append(group)\n",
    "    report[-1].append(fileName)\n",
    "    report[-1].append(len(pos))\n",
    "    report[-1].append(len(neg))\n",
    "    report[-1].append(round(aveTraceLen, 1))\n",
    "    report[-1].append(alphabet)\n",
    "\n",
    "    # Scarlet\n",
    "    if res[2][0] == '':\n",
    "        report[-1].append(f\"('OOT, {timeout})\")\n",
    "    elif res[2][0] == '[]':\n",
    "        report[-1].append(f\"('OOM', {res[2][1]})\")\n",
    "    else:\n",
    "        report[-1].append(f\"({c(res[2][0])}, {res[2][1]})\")\n",
    "\n",
    "    # GPU code\n",
    "    for i in range(len(allRes[0][3])):\n",
    "        for j in range(len(allRes[0][4])):\n",
    "            for k in range(len(allRes[0][5])):\n",
    "                report[-1].append(f\"({c(res[6][i][j][k])}, {res[8][i][j][k]})\")\n",
    "\n",
    "with open(\"report.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "    writer.writerows(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXRj1bRl3fhl"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "report = []\n",
    "for i in range(len(allRes[0][5])):\n",
    "    report.append([])\n",
    "    for j in range(len(allRes[0][6])):\n",
    "        report[-1].append([])\n",
    "        for k in range(len(allRes[0][7])):\n",
    "            report[-1][-1].append([0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for res in allRes:\n",
    "    for i in range(len(allRes[0][5])):\n",
    "        for j in range(len(allRes[0][6])):\n",
    "            for k in range(len(allRes[0][7])):\n",
    "                if res[9][i][j][k] == -1:\n",
    "                    report[i][j][k][3] += 1\n",
    "                elif res[9][i][j][k] == -2:\n",
    "                    report[i][j][k][4] += 1\n",
    "                elif res[9][i][j][k] == -3:\n",
    "                    report[i][j][k][5] += 1\n",
    "                elif res[9][i][j][k] == -4:\n",
    "                    report[i][j][k][6] += 1\n",
    "                else:\n",
    "                    report[i][j][k][0] += res[9][i][j][k]\n",
    "                    report[i][j][k][1] += res[10][i][j][k]\n",
    "                    report[i][j][k][2] += 1\n",
    "\n",
    "data1 = []\n",
    "headers = ['D&C', 'AppUnqChkType', 'WinSize', 'AveLTLCost', 'AveTime', 'Correct', 'OOT', 'OOM', 'TooLong', 'WrongLTL']\n",
    "\n",
    "for i in range(len(allRes[0][5])):\n",
    "    for j in range(len(allRes[0][6])):\n",
    "        for k in range(len(allRes[0][7])):\n",
    "            data1.append([str(allRes[0][5][i]),\n",
    "                          str(allRes[0][6][j]),\n",
    "                          str(allRes[0][7][k]),\n",
    "                          str(round(report[i][j][k][0] / report[i][j][k][2], 3)),\n",
    "                          str(round(report[i][j][k][1] / report[i][j][k][2], 3)) + 's',\n",
    "                          str(round(report[i][j][k][2] * 100 / len(allRes))) + '%',\n",
    "                          str(round(report[i][j][k][3] * 100 / len(allRes))) + '%',\n",
    "                          str(round(report[i][j][k][4] * 100 / len(allRes))) + '%',\n",
    "                          str(round(report[i][j][k][5] * 100 / len(allRes))) + '%',\n",
    "                          str(round(report[i][j][k][6] * 100 / len(allRes))) + '%'])\n",
    "\n",
    "table = tabulate(data1, headers, tablefmt=\"fancy_grid\", stralign=\"center\")\n",
    "\n",
    "with open(\"report.txt\", \"w\") as file:\n",
    "    file.write(table)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSBL0QlUxp5i"
   },
   "outputs": [],
   "source": [
    "maxTable = []\n",
    "for i in range(len(allRes[0][5])):\n",
    "    maxTable.append([])\n",
    "    for j in range(len(allRes[0][6])):\n",
    "        maxTable[-1].append(-1)\n",
    "\n",
    "for r in range(len(allRes)):\n",
    "    for i in range(len(allRes[0][5])):\n",
    "        for j in range(len(allRes[0][6])):\n",
    "            for k in range(len(allRes[0][7])):\n",
    "                if allRes[r][9][i][j][k] > maxTable[i][j]:\n",
    "                    maxTable[i][j] = allRes[r][9][i][j][k]\n",
    "\n",
    "for r in range(len(allRes)):\n",
    "    for i in range(len(allRes[0][5])):\n",
    "        for j in range(len(allRes[0][6])):\n",
    "            for k in range(len(allRes[0][7])):\n",
    "                if int(allRes[r][9][i][j][k]) in [-1, -2, -3, -4]:\n",
    "                    allRes[r][9][i][j][k] = round(1.1 * maxTable[i][j], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb9hcHpXT61E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"/content/figures\", exist_ok=True)\n",
    "\n",
    "filePaths = []\n",
    "for idx, res in enumerate(allRes):\n",
    "    filePaths.append(f\"Exp{idx}, ({res[0].split('/')[-1].split(', (')[-1]}\")\n",
    "\n",
    "for i in range(len(allRes[0][5])):\n",
    "    for j in range(len(allRes[0][6])):\n",
    "\n",
    "        LTLcosts = [res[9][i][j] for res in allRes]\n",
    "        transposed_LTLcosts = list(map(list, zip(*LTLcosts)))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(40,15))\n",
    "\n",
    "        for row, col in enumerate(transposed_LTLcosts):\n",
    "            ax.scatter(filePaths, col, label=f'WindowSize = {windows[row]}', s=windows[row]*150, zorder=2)\n",
    "\n",
    "        for k in range(len(filePaths)):\n",
    "            minCost = allRes[k][9][i][j][0]\n",
    "            for cost in allRes[k][9][i][j][1:]:\n",
    "                if cost < minCost:\n",
    "                    minCost = cost\n",
    "            plt.text(filePaths[k], minCost, f\"{minCost*100/allRes[k][-1]:.2f}%\", fontsize=8, ha='center', va='center', rotation=90)\n",
    "\n",
    "        plt.xticks(rotation=90)\n",
    "        ax.set_xlabel('Examples (#Alphabet, #P, #N, InputAveLen)', size = 20)\n",
    "        ax.set_ylabel('LTL Formula Size', size = 20)\n",
    "        ax.set_title(f\"{dcAlgoNames[i]}, AprUnqChkTyps = {AprUnqChkTyps[j]}\", size = 20)\n",
    "        plt.grid(axis=\"x\", color=(0.9, 0.9, 0.9), zorder=1)\n",
    "        handles,labels = ax.get_legend_handles_labels()\n",
    "        labels.reverse()\n",
    "        handles.reverse()\n",
    "        plt.legend(handles, labels, prop={'size': 20})\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/figures/{dcAlgoNames[i]}, {AprUnqChkTyps[j]}.png\")\n",
    "        plt.show\n",
    "\n",
    "shutil.make_archive(\"/content/figures\", 'zip', \"/content/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vFA1DjeEeGn"
   },
   "outputs": [],
   "source": [
    "def overFittedCase(alphabet, pos):\n",
    "    out = []\n",
    "    for p in pos:\n",
    "        trace = [t.split(',') for t in p.split(';')]\n",
    "        for i in range(len(trace)):\n",
    "            for j in range(len(alphabet)):\n",
    "                if trace[i][j] == '1':\n",
    "                    trace[i][j] = alphabet[j]\n",
    "                else:\n",
    "                    trace[i][j] = '~' + alphabet[j]\n",
    "        singleTraceLTL = LTLOfSingleTrace(alphabet, trace)\n",
    "        out.append(singleTraceLTL)\n",
    "    if len(out) == 1:\n",
    "        return out[0]\n",
    "    else:\n",
    "        return '|'.join([f\"({tr})\" for tr in out])\n",
    "\n",
    "all_file_paths = get_all_file_paths_in_folder(\"/content/paltlsy/benchmarks/Hamming_distance/delta=2\")\n",
    "all_file_paths.sort()\n",
    "all_file_paths.sort(key = len)\n",
    "\n",
    "for filePath in all_file_paths:\n",
    "\n",
    "    with open(filePath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "    neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "\n",
    "    overFittedLTL = overFittedCase(alphabet.split(','), neg)\n",
    "    overFittedCost = c(overFittedLTL)\n",
    "\n",
    "    print(overFittedCost, filePath.split(\"_\")[-1].split(\".\")[-2], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fClGVkp67MT5"
   },
   "source": [
    "# <strong>Hard Examples: Tiny Instances</strong>\n",
    "\n",
    "Examples need fewer than 126 bits, so the final results are minimal.\n",
    "\n",
    "NOTE: We should use a different GPU code that has negation for chars only and turn the `Until` off for comparing with the previous tools fairly.\n",
    "\n",
    "TODO: Add more explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxYGpfS1RmOX"
   },
   "outputs": [],
   "source": [
    "# Generating harder examples 1\n",
    "\n",
    "import os\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "def makeBenchmark(alphabet, le, Pnum, Nnum, repeat = 1, address = \"/content\"):\n",
    "\n",
    "    bvs = list(product([0, 1], repeat=len(alphabet)*le))\n",
    "\n",
    "    traceList = []\n",
    "    for bv in bvs:\n",
    "        trace = \"\"\n",
    "        for i in range(le):\n",
    "            trace += str(bv[2*i]) + ',' + str(bv[2*i+1]) + ';'\n",
    "        trace = trace[:-1]\n",
    "        traceList.append(trace)\n",
    "    if Pnum + Nnum > len(traceList):\n",
    "        return \"error\", \"error\"\n",
    "\n",
    "    unique_tuples = set()\n",
    "\n",
    "    while len(unique_tuples) < repeat:\n",
    "\n",
    "        PN = random.sample(traceList, Pnum + Nnum)\n",
    "        P = set(random.sample(PN, Pnum))\n",
    "        N = set(PN) - set(P)\n",
    "\n",
    "        unique_tuples.add((frozenset(P), frozenset(N)))\n",
    "\n",
    "    for i, (P, N) in enumerate(unique_tuples):\n",
    "        P = list(P)\n",
    "        N = list(N)\n",
    "        with open(f\"{address}/len={str(le)}_exp{str(i)}.trace\", 'w') as file:\n",
    "            for trace in P:\n",
    "                file.write(f\"{trace}\\n\")\n",
    "            file.write(\"---\\n\")\n",
    "            for trace in N:\n",
    "                file.write(f\"{trace}\\n\")\n",
    "            file.write(\"---\\n\")\n",
    "            file.write(\"All Operators\\n\")\n",
    "            file.write(\"---\\n\")\n",
    "            file.write(\",\".join(alphabet))\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "alphabet = ['a', 'b']\n",
    "os.makedirs(\"/content/tiny_hard\", exist_ok=True)\n",
    "for le in range(2, 4 + 1):\n",
    "    address = \"/content/tiny_hard/len=\" + str(le)\n",
    "    os.makedirs(address, exist_ok=True)\n",
    "    makeBenchmark(alphabet, le, 8, 8, 100, address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4aL9q6ErUn1"
   },
   "outputs": [],
   "source": [
    "# Runnig the hard example 1\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def get_all_file_paths_in_folder(path):\n",
    "    all_file_paths = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if \".trace\" in file_path:\n",
    "                all_file_paths.append(file_path)\n",
    "    return all_file_paths\n",
    "\n",
    "all_file_paths = get_all_file_paths_in_folder(\"/content/tiny_hard\")\n",
    "\n",
    "RES = []\n",
    "\n",
    "for filePath in all_file_paths:\n",
    "\n",
    "    with open(filePath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "    neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "    alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "    f = open(\"subInput\", 'w')\n",
    "    for p in pos:\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    for n in neg:\n",
    "        f.write(str(n))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(\"All operators\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(alphabet)\n",
    "    f.close()\n",
    "\n",
    "    output = subprocess.run(\n",
    "        [\"./ltli6463\",\n",
    "        \"subInput\",\n",
    "        '1', '1', '1', '1', '1', '1', '1', '500', '500', '1'], #----------------------------- check\n",
    "        stdout = subprocess.PIPE,\n",
    "        stderr = subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    ltl = str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-2].split()[-1][1:-1]\n",
    "    cst = int(str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-5].split()[-1])\n",
    "    time = str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-4].split()[-2]\n",
    "\n",
    "    RES.append([filePath, time, cst, ltl])\n",
    "\n",
    "    print(filePath)\n",
    "    print(time, cst, ltl)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEqzaOlv2HJg"
   },
   "outputs": [],
   "source": [
    "RES.sort(key = lambda x : x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDoQI7BZ49jl"
   },
   "outputs": [],
   "source": [
    "RES2 = []\n",
    "for res in RES:\n",
    "    if res[-1] != \"not_found\":\n",
    "        RES2.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gnHKkXX6LMz"
   },
   "outputs": [],
   "source": [
    "RES2[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKvl6Dfr0CDg"
   },
   "source": [
    "# <strong>Relaxed Uniqueness Check Challenger</strong>\n",
    "\n",
    "TODO: Add some explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdkfN9G_FeVm"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ! apt install mona\n",
    "# ! python3 -m pip install Scarlet-ltl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyvAdihe16Rp"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from Scarlet.genBenchmarks import SampleGenerator\n",
    "\n",
    "def reArrangeFormula(formula):\n",
    "\n",
    "    i = 0\n",
    "    if formula[0] == '(':\n",
    "        p = 1\n",
    "        i += 1\n",
    "        while p != 0:\n",
    "            if formula[i] == '(':\n",
    "                p += 1\n",
    "            elif formula[i] == ')':\n",
    "                p -= 1\n",
    "            i += 1\n",
    "\n",
    "    if formula[i] == '~':\n",
    "        return f\"!({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == '&':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"&({l}, {r})\"\n",
    "\n",
    "    elif formula[i] == '|':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"|({l}, {r})\"\n",
    "\n",
    "    elif formula[i] == 'X':\n",
    "        return f\"X({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'F':\n",
    "        return f\"F({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'G':\n",
    "        return f\"G({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'U':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"U({l}, {r})\"\n",
    "\n",
    "    return formula\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "def makeSample(formula, alphabet, numOfTraces, lenOfTraces):\n",
    "\n",
    "    with open(\"formula.txt\", \"w\") as file:\n",
    "        file.write(f\"{reArrangeFormula(formula)};{alphabet.replace(' ', '')}\")\n",
    "\n",
    "    with HiddenPrints():\n",
    "        generator = SampleGenerator(formula_file = \"formula.txt\", output_folder = \"sampler\", sample_sizes = [(numOfTraces, numOfTraces)], trace_lengths = [(lenOfTraces, lenOfTraces)])\n",
    "        generator.generate()\n",
    "\n",
    "    folder_path = \"/content/sampler/TracesFiles\"\n",
    "\n",
    "    for filePath in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filePath)\n",
    "        with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "    pp = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "    nn = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "\n",
    "    return pp, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNzdR9Ri7gp2"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "\n",
    "def AprUnqChkAlgChallenger(pos, neg, alphabet, trLen):\n",
    "\n",
    "    # Making the initial formula\n",
    "\n",
    "    f = open(\"subInput\", 'w')\n",
    "    for p in pos:\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    for n in neg:\n",
    "        f.write(str(n))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(\"All operators\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(alphabet)\n",
    "    f.close()\n",
    "\n",
    "    # it does not use apr algos as it fits the mem\n",
    "    # so, any index is fine\n",
    "    output = subprocess.run(\n",
    "        [\"./ltli6463\",\n",
    "        \"subInput\",\n",
    "        '1', '1', '1', '1', '1', '1', '1', '500', '500', '1', '2'],\n",
    "        stdout = subprocess.PIPE,\n",
    "        stderr = subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    initialLTL = str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-2].split()[-1][1:-1]\n",
    "    if 'not_found' in initialLTL:\n",
    "        print('No initial LTL formula')\n",
    "        return 'error'\n",
    "    print('Intial LTL formula: ', initialLTL)\n",
    "    print()\n",
    "    longP, longN = makeSample(initialLTL, alphabet, 32 - len(pos), trLen)\n",
    "\n",
    "    # Making the next formulas\n",
    "\n",
    "    out = [initialLTL]\n",
    "\n",
    "    for i in range(32 - len(pos)):\n",
    "\n",
    "        out.append([])\n",
    "\n",
    "        pos.append(longP[i])\n",
    "        neg.append(longN[i])\n",
    "\n",
    "        f = open(\"subInput\", 'w')\n",
    "        for p in pos:\n",
    "            f.write(str(p))\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"---\\n\")\n",
    "        for n in neg:\n",
    "            f.write(str(n))\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"---\\n\")\n",
    "        f.write(\"All operators\\n\")\n",
    "        f.write(\"---\\n\")\n",
    "        f.write(alphabet)\n",
    "        f.close()\n",
    "\n",
    "        print(f\"(#P, #N) = ({len(pos)}, {len(neg)})\")\n",
    "\n",
    "        if len(pos) == 32:\n",
    "            ! cp subInput xx\n",
    "\n",
    "        for j in range(1, 3 + 1):\n",
    "\n",
    "            output = subprocess.run(\n",
    "                [\"./ltli6463\",\n",
    "                \"subInput\",\n",
    "                '1', '1', '1', '1', '1', '1', '1', '500', '500', str(j), '2'],\n",
    "                stdout = subprocess.PIPE,\n",
    "                stderr = subprocess.PIPE\n",
    "            )\n",
    "\n",
    "            ltl = str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-2].split()[-1][1:-1]\n",
    "            time = round(float(str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-4].split()[-2]), 3)\n",
    "\n",
    "            out[-1].append([ltl, time])\n",
    "\n",
    "            print(f\"AprAlgo = {j},\\t{ltl},\\ttime = {time}\")\n",
    "        print()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p_X4DiEV1ZG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "random.seed(0)\n",
    "alphabet = ['a', 'b']\n",
    "size = 500\n",
    "Pnum = 8\n",
    "Nnum = 8\n",
    "\n",
    "bvs = []\n",
    "for le in range(2, 5 + 1):\n",
    "    bvs += list(product([0, 1], repeat=2*le))\n",
    "\n",
    "traceList = []\n",
    "for bv in bvs:\n",
    "    trace = \"\"\n",
    "    for i in range(int(len(bv) / 2)):\n",
    "        trace += str(bv[2*i]) + ',' + str(bv[2*i+1]) + ';'\n",
    "    trace = trace[:-1]\n",
    "    traceList.append(trace)\n",
    "\n",
    "data = []\n",
    "error = []\n",
    "\n",
    "with tqdm(total = size) as pbar:\n",
    "\n",
    "    for i in range(size):\n",
    "\n",
    "        PN = random.sample(traceList, Pnum + Nnum)\n",
    "        P = random.sample(PN, Pnum)\n",
    "        N = list(set(PN) - set(P))\n",
    "\n",
    "        try:\n",
    "            output = AprUnqChkAlgChallenger(P, N, ','.join(alphabet), 63)\n",
    "            if not 'error' in output:\n",
    "                data.append(output)\n",
    "        except:\n",
    "            # with open('/content/formula.txt', 'r') as file:\n",
    "            #     error.append(file.read())\n",
    "            pass\n",
    "\n",
    "        print()\n",
    "        pbar.update(1)\n",
    "        print()\n",
    "\n",
    "        # backup\n",
    "        with open(\"/content/data.txt\", 'w') as file:\n",
    "            file.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOP1lI_USCYM"
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmHf-D1tSFUa"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjKSmv_RJFsj"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"/content/data.txt\", 'r') as file:\n",
    "#     data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02jvp_xRdxr0"
   },
   "outputs": [],
   "source": [
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6LOTYZqd_Qy"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "report = []\n",
    "\n",
    "for row in range(len(data[0]) - 1):\n",
    "    report.append([[0, 0, 0], [0, 0, 0], [0, 0, 0], 0])\n",
    "\n",
    "for row in data:\n",
    "    minCost = c(row[0])\n",
    "    for idx, info in enumerate(row[1:]):\n",
    "        if 'not_found' in [info[0][0], info[1][0], info[2][0]]:\n",
    "            for i in range(3):\n",
    "                if 'not_found' in info[i][0]:\n",
    "                    report[idx][i][2] += 1\n",
    "        else:\n",
    "            for i in range(3):\n",
    "                perc = (c(info[i][0]) - minCost) * 100 / minCost\n",
    "                time = info[i][1]\n",
    "                report[idx][i][0] += perc\n",
    "                report[idx][i][1] += time\n",
    "            report[idx][3] += 1\n",
    "\n",
    "for i in range(len(report)):\n",
    "    for j in range(3):\n",
    "        report[i][j][0] = round(report[i][j][0] / report[idx][3], 1)\n",
    "        report[i][j][1] = round(report[i][j][1] / report[idx][3], 3)\n",
    "        report[i][j][2] = round(report[i][j][2] * 100 / len(data), 1)\n",
    "\n",
    "for i in range(len(report)):\n",
    "    report[i] = [x for info in report[i][:-1] for x in info]\n",
    "\n",
    "for i in range(len(report)):\n",
    "    report[i] = [str(info) for info in report[i]]\n",
    "\n",
    "for i in range(len(report)):\n",
    "    for j in range(3):\n",
    "        report[i][j * 3    ] += '%'\n",
    "        report[i][j * 3 + 1] += 's'\n",
    "        report[i][j * 3 + 2] += '%'\n",
    "\n",
    "for i in range(9, 32 + 1):\n",
    "    report[i - 9].insert(0, f\"(P, N) = ({i}, {i})\")\n",
    "\n",
    "AprUnqChkTyps = ['firstBitPlusStrides', 'firstKPercent', 'MuellerHash']\n",
    "\n",
    "headers1 = ['']\n",
    "for i in range(3):\n",
    "    subHeader = []\n",
    "    for j in range(2):\n",
    "        subHeader.append(AprUnqChkTyps[i])\n",
    "    headers1 += subHeader\n",
    "\n",
    "headers2 = ['SizeOfInput']\n",
    "for i in range(3):\n",
    "    # headers2 += ['AveExtraCost', 'AveTime', 'OOM']\n",
    "    headers2 += ['AveExtraCost', 'OOM']\n",
    "\n",
    "report2 = []\n",
    "# removing time for now\n",
    "for row in report:\n",
    "    report2.append([])\n",
    "    for item in row:\n",
    "        if not 's' in item:\n",
    "            report2[-1].append(item)\n",
    "\n",
    "with open(\"report.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers1)\n",
    "    writer.writerow(headers2)\n",
    "    writer.writerows(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VU4_silp--61"
   },
   "outputs": [],
   "source": [
    "headers1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlRqGDlBPZya"
   },
   "source": [
    "# <strong>Reading Haming Prints</strong>\n",
    "\n",
    "TODO: Add some explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDeIPxbN4Hy3"
   },
   "outputs": [],
   "source": [
    "# file_path = \"/content/delta=1.txt\"\n",
    "# with open(file_path, 'r') as file:\n",
    "#     content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jVH1uggnzS-"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# COSTpattern = r'\\[(-?\\d+), (-?\\d+), (-?\\d+)\\]'\n",
    "# COSTmatches = re.findall(COSTpattern, content)\n",
    "\n",
    "# TIMEpattern = r'\\[(-?\\d+\\.\\d+), (-?\\d+\\.\\d+), (-?\\d+\\.\\d+)\\]'\n",
    "# TIMEmatches = re.findall(TIMEpattern, content)\n",
    "\n",
    "# COSTresults = []\n",
    "# for match in COSTmatches:\n",
    "#     COSTresults.append(list(map(int, match)))\n",
    "\n",
    "# TIMEresults = []\n",
    "# for match in TIMEmatches:\n",
    "#     TIMEresults.append(list(map(float, match)))\n",
    "\n",
    "# costs = []\n",
    "# for i in range(0, len(COSTresults), 3):\n",
    "#     costs.append(COSTresults[i:i+3])\n",
    "# costRes = []\n",
    "# for i in range(0, len(costs), 3):\n",
    "#     costRes.append(costs[i:i+3])\n",
    "\n",
    "# times = []\n",
    "# for i in range(0, len(TIMEresults), 3):\n",
    "#     times.append(TIMEresults[i:i+3])\n",
    "# timeRes = []\n",
    "# for i in range(0, len(times), 3):\n",
    "#     timeRes.append(times[i:i+3])\n",
    "\n",
    "# dcAlgoNames = ['MV D&C', 'MB D&C Type2', 'MB D&C Type1']\n",
    "# AprUnqChkTyps = ['firstBitPlusStrides', 'firstKPercent', 'MuellerHash'] # Note: you cannnot change this unless you get the indices\n",
    "# windows = [64, 32, 16]\n",
    "\n",
    "# allRes = []\n",
    "# for i in range(len(costRes)):\n",
    "#     allRes.append([f\"delta=?,Len={(i + 1) * 3}\", '', '', '', '', dcAlgoNames, AprUnqChkTyps, windows, '', costRes[i], timeRes[i], '', ''])\n",
    "\n",
    "# import csv\n",
    "\n",
    "# report = []\n",
    "\n",
    "# dc = ['MV', 'MB2', 'MB1']\n",
    "# ap = ['FBS', 'FKP', 'Hsh']\n",
    "# wn = ['64', '32', '16']\n",
    "\n",
    "# headers = ['filePath', 'Scarlet']\n",
    "\n",
    "# for i in range(len(dc)):\n",
    "#     for j in range(len(ap)):\n",
    "#         for k in range(len(wn)):\n",
    "#             headers.append(f\"{dc[i]}-{ap[j]}-{wn[k]}\")\n",
    "\n",
    "# for res in allRes:\n",
    "\n",
    "#     report.append([])\n",
    "\n",
    "#     report[-1].append(res[0])\n",
    "\n",
    "#     # Scarlet\n",
    "#     report[-1].append(f\"(0, 2000)\")\n",
    "\n",
    "#     # GPU code\n",
    "#     for i in range(len(dc)):\n",
    "#         for j in range(len(ap)):\n",
    "#             for k in range(len(wn)):\n",
    "#                 if res[9][i][j][k] != -1:\n",
    "#                     report[-1].append(f\"({res[9][i][j][k]}, {res[10][i][j][k]})\")\n",
    "#                 else:\n",
    "#                     report[-1].append(f\"(0, 2000)\")\n",
    "\n",
    "# with open(\"report.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     writer.writerows(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giLBIgwoTuWT"
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# all_file_paths = get_all_file_paths_in_folder(\"/content/paltlsy/benchmarks/Hamming_distance/delta=2\")\n",
    "# all_file_paths.sort()\n",
    "# all_file_paths.sort(key = len)\n",
    "\n",
    "# table = []\n",
    "\n",
    "# for i, filePath in enumerate(all_file_paths):\n",
    "\n",
    "#     with open(filePath, 'r') as file:\n",
    "#             content = file.read()\n",
    "\n",
    "#     pos = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "#     neg = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "#     alphabet = content.split(\"\\n\")[-1]\n",
    "\n",
    "#     sumTraceLen = 0\n",
    "#     for p in pos:\n",
    "#         sumTraceLen += len(p.split(';'))\n",
    "#     for n in neg:\n",
    "#         sumTraceLen += len(n.split(';'))\n",
    "#     aveTraceLen = sumTraceLen / (len(pos) + len(neg))\n",
    "\n",
    "#     table.append(['delta=2', f\"len={(i + 1) * 3}\", len(pos), len(neg), round(aveTraceLen, 1), alphabet])\n",
    "\n",
    "# with open(\"rep.csv\", mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerows(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0rfCWxjY2w-"
   },
   "source": [
    "# <strong>Hamming Figure Maker</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evpx_1BhZHuf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bPuHT-Kqe5M"
   },
   "outputs": [],
   "source": [
    "# delta 1, costs\n",
    "\n",
    "file_path = '/content/delta12colab.xlsx'\n",
    "df1 = pd.read_excel(file_path, header=None, usecols=\"F:Q\", skiprows=1, nrows=16)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqUfuo2rhzsU"
   },
   "outputs": [],
   "source": [
    "# delta 1, costs\n",
    "\n",
    "col = []\n",
    "\n",
    "DC = ['RS', 'DS']\n",
    "AP = ['FKP', 'Hsh']\n",
    "WN = ['64', '32', '16']\n",
    "\n",
    "for dc in DC:\n",
    "    for ap in AP:\n",
    "        for wn in WN:\n",
    "            col.append(f\"{dc}-{ap}-{wn}\")\n",
    "\n",
    "df1.columns = col\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "NegSz = [6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "x_axis_labels = [f'({3 * (i + 1)}, {NegSz[i]})' for i in range(16)]\n",
    "\n",
    "for column in df1.columns[:6]:\n",
    "    plt.plot(x_axis_labels, df1[column], marker='x', label=column, linestyle='-')\n",
    "\n",
    "for column in df1.columns[6:]:\n",
    "    plt.plot(x_axis_labels, df1[column], marker='s', label=column, linestyle='-')\n",
    "\n",
    "plt.axhline(y=1.0, color='black', linestyle='--')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('(TrLen, #N)')\n",
    "plt.ylabel('Found LTL Cost / Over-fitted Cost')\n",
    "plt.title('Delta = 1')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('d1c.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQsX6LCUq7Zs"
   },
   "outputs": [],
   "source": [
    "# delta 2, costs\n",
    "\n",
    "file_path = '/content/delta12colab.xlsx'\n",
    "df2 = pd.read_excel(file_path, header=None, usecols=\"F:Q\", skiprows=19, nrows=16)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7VufYvYrUir"
   },
   "outputs": [],
   "source": [
    "# delta 2, costs\n",
    "\n",
    "col = []\n",
    "\n",
    "DC = ['RS', 'DS']\n",
    "AP = ['FKP', 'Hsh']\n",
    "WN = ['64', '32', '16']\n",
    "\n",
    "for dc in DC:\n",
    "    for ap in AP:\n",
    "        for wn in WN:\n",
    "            col.append(f\"{dc}-{ap}-{wn}\")\n",
    "\n",
    "df2.columns = col\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "NegSz = [15, 66, 153, 276, 435, 630, 861, 1128, 1431, 1770, 2145, 2556, 3003, 3486, 4005, 4560]\n",
    "x_axis_labels = [f'({3 * (i + 1)}, {NegSz[i]})' for i in range(16)]\n",
    "\n",
    "for column in df2.columns[:6]:\n",
    "    plt.plot(x_axis_labels, df2[column], marker='x', label=column, linestyle='-')\n",
    "\n",
    "for column in df2.columns[6:]:\n",
    "    plt.plot(x_axis_labels, df2[column], marker='s', label=column, linestyle='-')\n",
    "\n",
    "plt.axhline(y=4.0, color='red',   linestyle='--')\n",
    "plt.axhline(y=1.0, color='black', linestyle='--')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('(TrLen, #N)')\n",
    "plt.ylabel('Found LTL Cost / Over-fitted Cost')\n",
    "plt.title('Delta = 2')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0, 0.95))\n",
    "\n",
    "plt.savefig('d2c.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmsXkUN0wFeb"
   },
   "outputs": [],
   "source": [
    "# delta 1, time\n",
    "\n",
    "file_path = '/content/delta12colab.xlsx'\n",
    "df3 = pd.read_excel(file_path, header=None, usecols=\"S:AD\", skiprows=1, nrows=16)\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDOV-x5EwloM"
   },
   "outputs": [],
   "source": [
    "# delta 1, time\n",
    "\n",
    "col = []\n",
    "\n",
    "DC = ['RS', 'DS']\n",
    "AP = ['FKP', 'Hsh']\n",
    "WN = ['64', '32', '16']\n",
    "\n",
    "for dc in DC:\n",
    "    for ap in AP:\n",
    "        for wn in WN:\n",
    "            col.append(f\"{dc}-{ap}-{wn}\")\n",
    "\n",
    "df3.columns = col\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "NegSz = [6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "x_axis_labels = [f'({3 * (i + 1)}, {NegSz[i]})' for i in range(16)]\n",
    "\n",
    "for column in df3.columns[:6]:\n",
    "    plt.plot(x_axis_labels, df3[column], marker='x', label=column, linestyle='-')\n",
    "\n",
    "for column in df3.columns[6:]:\n",
    "    plt.plot(x_axis_labels, df3[column], marker='s', label=column, linestyle='-')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('(TrLen, #N)')\n",
    "plt.ylabel('Running Time (s)')\n",
    "plt.title('Delta = 1')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('d1t.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP3bE6nJxOpn"
   },
   "outputs": [],
   "source": [
    "# delta 2, time\n",
    "\n",
    "file_path = '/content/delta12colab.xlsx'\n",
    "df4 = pd.read_excel(file_path, header=None, usecols=\"S:AD\", skiprows=19, nrows=16)\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alYYmnhOxatR"
   },
   "outputs": [],
   "source": [
    "# delta 2, time\n",
    "\n",
    "col = []\n",
    "\n",
    "DC = ['RS', 'DS']\n",
    "AP = ['FKP', 'Hsh']\n",
    "WN = ['64', '32', '16']\n",
    "\n",
    "for dc in DC:\n",
    "    for ap in AP:\n",
    "        for wn in WN:\n",
    "            col.append(f\"{dc}-{ap}-{wn}\")\n",
    "\n",
    "df4.columns = col\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "NegSz = [15, 66, 153, 276, 435, 630, 861, 1128, 1431, 1770, 2145, 2556, 3003, 3486, 4005, 4560]\n",
    "x_axis_labels = [f'({3 * (i + 1)}, {NegSz[i]})' for i in range(16)]\n",
    "\n",
    "for column in df4.columns[:6]:\n",
    "    plt.plot(x_axis_labels, df4[column], marker='x', label=column, linestyle='-')\n",
    "\n",
    "for column in df4.columns[6:]:\n",
    "    plt.plot(x_axis_labels, df4[column], marker='s', label=column, linestyle='-')\n",
    "\n",
    "plt.axhline(y=400, color='red',   linestyle='--')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('(TrLen, #N)')\n",
    "plt.ylabel('Running Time (s)')\n",
    "plt.title('Delta = 2')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(0, 0.95))\n",
    "\n",
    "plt.savefig('d2t.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9KhivomdOYX"
   },
   "source": [
    "# <strong>Scaling</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpwxOWJNdOJy"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/paltlsy/code')\n",
    "import json\n",
    "from dc import *\n",
    "import signal\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from Scarlet.genBenchmarks import SampleGenerator\n",
    "\n",
    "def runWithTimeout(func, args, timeout):\n",
    "    class TimeoutError(Exception):\n",
    "        pass\n",
    "    def handler(signum, frame):\n",
    "        raise TimeoutError()\n",
    "    signal.signal(signal.SIGALRM, handler)\n",
    "    signal.alarm(timeout)\n",
    "    try:\n",
    "        result = func(*args)\n",
    "    except TimeoutError as exc:\n",
    "        result = \"Function timed out.\"\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "    return result\n",
    "\n",
    "def reArrangeFormula(formula):\n",
    "\n",
    "    i = 0\n",
    "    if formula[0] == '(':\n",
    "        p = 1\n",
    "        i += 1\n",
    "        while p != 0:\n",
    "            if formula[i] == '(':\n",
    "                p += 1\n",
    "            elif formula[i] == ')':\n",
    "                p -= 1\n",
    "            i += 1\n",
    "\n",
    "    if formula[i] == '~':\n",
    "        return f\"!({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == '&':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"&({l}, {r})\"\n",
    "\n",
    "    elif formula[i] == '|':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"|({l}, {r})\"\n",
    "\n",
    "    elif formula[i] == 'X':\n",
    "        return f\"X({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'F':\n",
    "        return f\"F({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'G':\n",
    "        return f\"G({reArrangeFormula(formula[2:-1])})\"\n",
    "\n",
    "    elif formula[i] == 'U':\n",
    "        l = reArrangeFormula(formula[1:i-1])\n",
    "        r = reArrangeFormula(formula[i+2:-1])\n",
    "        return f\"U({l}, {r})\"\n",
    "\n",
    "    return formula\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "def makeSample(formula, alphabet, numOfTraces, lenOfTraces):\n",
    "\n",
    "    with open(\"formula.txt\", \"w\") as file:\n",
    "        file.write(f\"{reArrangeFormula(formula)};{alphabet.replace(' ', '')}\")\n",
    "\n",
    "    with HiddenPrints():\n",
    "        generator = SampleGenerator(formula_file = \"formula.txt\", output_folder = \"sampler\", sample_sizes = [(numOfTraces, numOfTraces)], trace_lengths = [(lenOfTraces, lenOfTraces)])\n",
    "        generator.generate()\n",
    "\n",
    "    folder_path = \"/content/sampler/TracesFiles\"\n",
    "\n",
    "    for filePath in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filePath)\n",
    "        with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "    pp = content.split(\"\\n\")[:content.split(\"\\n\").index(\"---\")]\n",
    "    nn = content.split(\"\\n\")[content.split(\"\\n\").index(\"---\")+1:-4]\n",
    "\n",
    "    return pp, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuEV1mRHhpp0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import subprocess\n",
    "\n",
    "random.seed(0)\n",
    "alphabet = ['a', 'b']\n",
    "\n",
    "Pnum = 5\n",
    "Nnum = 5\n",
    "\n",
    "bvs = []\n",
    "for le in range(2, 5 + 1):\n",
    "    bvs += list(product([0, 1], repeat=2*le))\n",
    "\n",
    "traceList = []\n",
    "for bv in bvs:\n",
    "    trace = \"\"\n",
    "    for i in range(int(len(bv) / 2)):\n",
    "        trace += str(bv[2*i]) + ',' + str(bv[2*i+1]) + ';'\n",
    "    trace = trace[:-1]\n",
    "    traceList.append(trace)\n",
    "\n",
    "data = []\n",
    "error = []\n",
    "\n",
    "PN = random.sample(traceList, Pnum + Nnum)\n",
    "pos = random.sample(PN, Pnum)\n",
    "neg = list(set(PN) - set(pos))\n",
    "alphabet = ','.join(alphabet)\n",
    "\n",
    "f = open(\"subInput\", 'w')\n",
    "for p in pos:\n",
    "    f.write(str(p))\n",
    "    f.write(\"\\n\")\n",
    "f.write(\"---\\n\")\n",
    "for n in neg:\n",
    "    f.write(str(n))\n",
    "    f.write(\"\\n\")\n",
    "f.write(\"---\\n\")\n",
    "f.write(\"All operators\\n\")\n",
    "f.write(\"---\\n\")\n",
    "f.write(alphabet)\n",
    "f.close()\n",
    "\n",
    "output = subprocess.run(\n",
    "[\"./ltli6463\",\n",
    "\"subInput\",\n",
    "'1', '1', '1', '1', '1', '1', '1', '500', '500', '3', '2'],\n",
    "stdout = subprocess.PIPE,\n",
    "stderr = subprocess.PIPE\n",
    ")\n",
    "\n",
    "initialLTL = str(output.stdout).replace('\\\\n', '\\n')[1:].split(\"\\n\")[-2].split()[-1][1:-1]\n",
    "if 'not_found' in initialLTL:\n",
    "    print('No initial LTL formula')\n",
    "\n",
    "print('Intial LTL formula: ', initialLTL)\n",
    "print()\n",
    "longP, longN = makeSample(initialLTL, alphabet, 131072 - 5, 63)\n",
    "print(len(longP), len(longN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJVjwlpGUjHO"
   },
   "outputs": [],
   "source": [
    "pos += longP\n",
    "neg += longN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bo-gO9wgT1N"
   },
   "outputs": [],
   "source": [
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBgj7MbxchJU"
   },
   "outputs": [],
   "source": [
    "# alphabet = \"a,b\"\n",
    "# NegTyp = 2\n",
    "# maxCost = 500\n",
    "# costfun = [1, 1, 1, 1, 1, 1, 1, maxCost]\n",
    "\n",
    "# DC3(64, pos, neg, alphabet, costfun, maxCost, 3, NegTyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rc23xOd7XAzW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"pos.json\", 'r') as json_file:\n",
    "    pos = json.load(json_file)\n",
    "\n",
    "with open(\"neg.json\", 'r') as json_file:\n",
    "    neg = json.load(json_file)\n",
    "\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW8hHZ8-VPlQ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "alphabet = \"a,b\"\n",
    "NegTyp = 2\n",
    "maxCost = 500\n",
    "costfun = [1, 1, 1, 1, 1, 1, 1, maxCost]\n",
    "\n",
    "timeout = 60\n",
    "\n",
    "i = 2**3\n",
    "while i < len(pos):\n",
    "    print(f\"(#P, #N) = ({i}, {i}):\")\n",
    "    p = pos[:i+1]\n",
    "    n = neg[:i+1]\n",
    "    start_time = time.time()\n",
    "    r = runWithTimeout(DC3, [64, p, n, alphabet, costfun, maxCost, 3, NegTyp], timeout=timeout)\n",
    "    end_time = time.time()\n",
    "    t = round(end_time - start_time, 2)\n",
    "    print(t, c(r), r)\n",
    "    i *= 2\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9CymIrfdxXx"
   },
   "outputs": [],
   "source": [
    "# Scarlet\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from Scarlet.ltllearner import LTLlearner\n",
    "\n",
    "def c(ltl):\n",
    "    return(len(ltl.replace(',', '').replace(' ', '').replace('(', '').replace(')', '')))\n",
    "\n",
    "def scarlet(input_file_path):\n",
    "\n",
    "    # timeout is something big enough as we control the timing from somewhere out of the Scarlet\n",
    "    learner = LTLlearner(input_file = input_file_path, timeout = 100000)\n",
    "\n",
    "    out = learner.learn()\n",
    "\n",
    "    try:\n",
    "        return str(out[0])\n",
    "    except:\n",
    "        return str(out)\n",
    "\n",
    "folder_path = \"/content/Scarlet\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "alphabet = \"a,b\"\n",
    "timeout = 100000 # like infinity\n",
    "\n",
    "i = 2**17\n",
    "while i < len(pos):\n",
    "    print(f\"(#P, #N) = ({i}, {i}):\")\n",
    "\n",
    "    f = open(\"subInput\", 'w')\n",
    "    for p in pos[:i+1]:\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    for n in neg[:i+1]:\n",
    "        f.write(str(n))\n",
    "        f.write(\"\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(\"All operators\\n\")\n",
    "    f.write(\"---\\n\")\n",
    "    f.write(alphabet)\n",
    "    f.close()\n",
    "\n",
    "    start_time = time.time()\n",
    "    r = scarlet(\"subInput\")\n",
    "    # r = runWithTimeout(scarlet, [\"subInput\"], timeout=timeout)\n",
    "    end_time = time.time()\n",
    "    t = round(end_time - start_time, 2)\n",
    "    print(t, c(r), r)\n",
    "    i = int(i/2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPX5h4ObmiRT"
   },
   "source": [
    "# <strong>CPU and GPU Spec</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m--9x6TTmy0t"
   },
   "outputs": [],
   "source": [
    "from psutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crAwnMSinA7b"
   },
   "outputs": [],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69TH0yCvnCyy"
   },
   "outputs": [],
   "source": [
    "cpu_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVZmraFhnWGf"
   },
   "outputs": [],
   "source": [
    "!lscpu |grep 'Model name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDujByjQopA7"
   },
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pnq-5IRXnIIo"
   },
   "outputs": [],
   "source": [
    "virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_Y9PyIYnI14"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEKdFaJsnSk-"
   },
   "outputs": [],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHXHzUWZnEZJ"
   },
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6GW74ZfTNKj"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf8rKlcxTNuV"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELMm1--ZVkFo"
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMHF5JbnrE0IY4tayO8izUr",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
